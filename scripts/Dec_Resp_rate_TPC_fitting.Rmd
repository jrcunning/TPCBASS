---
title: "Respiration TPC fitting"
authors: Hollie Putnam 
edited by: Hollie Putnam 
date: 20220829
output: html_document
---

# PR data from heatwave timepoint 1 corals
```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

## install packages if you dont already have them in your library
if (!require("devtools")) install.packages("devtools")
if (!require("furrr")) install.packages("furrr")
if (!require("future")) install.packages("future")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("gridExtra")) install.packages("gridExtra")
if (!require("ggpubr")) install.packages("ggpubr")
if (!require("lubridate")) install.packages("lubridate")
if (!require("cowplot")) install.packages("cowplot")
if (!require("ggstatsplot")) install.packages("ggstatsplot")
if ("rTPC" %in% rownames(installed.packages()) == 'FALSE') remotes::install_github("padpadpadpad/rTPC")
if ("nls.multstart" %in% rownames(installed.packages()) == 'FALSE') install.packages('nls.multstart')
if ("broom" %in% rownames(installed.packages()) == 'FALSE') install.packages('broom') 

## load libraries
library('devtools')
library('tidyverse')
library('gridExtra')
library('ggpubr')
library('lubridate')
library('cowplot')
library('ggstatsplot')
library('rTPC')
library('nls.multstart')
library('broom')
library('car')
library('scales')
library('future') ## libraries for parallel processing
library('furrr') ## libraries for parallel processing
```

## Import data
```{r, warning = FALSE}
Respdata <- read.csv("data/TPC/Dec_Resp_extracted_rates.csv")
```

TPC fitting 
Padifeld et al **rTPC and nls.multstart: A new pipeline to fit thermal performance curves in r**  
https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13585  

Sharpe Schoolfield 1981 model
Schoolfield, R. M., Sharpe, P. J. H., & Magnuson, C. E. (1981). Non-linear regression of biological temperature-dependent rate models based on absolute reaction-rate theory. Journal of theoretical biology, 88(4), 719-731. https://doi.org/10.1016/0022-5193(81)90246-0

```{r}
#Respiration
Respdata$temp <- as.numeric(Respdata$Temp.Cat)
Respdata$micromol.cm2.h <- -Respdata$micromol.cm2.h
#Respdata$micromol.cm2.h <- replace(Respdata$micromol.cm2.h, Respdata$micromol.cm2.h<0,0)
Respdata$transformed.rate <- log10(Respdata$micromol.cm2.h+1)

# choose model
get_model_names()
#sharpeschoolhigh_1981

# get start vals
start_vals <- get_start_vals(Respdata$temp,Respdata$transformed.rate, model_name = 'sharpeschoolhigh_1981')

# get limits
low_lims <- get_lower_lims(Respdata$temp,Respdata$transformed.rate, model_name = 'sharpeschoolhigh_1981')
upper_lims <- get_upper_lims(Respdata$temp,Respdata$transformed.rate, model_name = 'sharpeschoolhigh_1981')

#view values
start_vals
low_lims
upper_lims
```

#individal fitting
```{r}

# when scaling up our code to fit hundreds of models, its nice to have a progress bar
# edit nls_multstart to allow for a progress bar
nls_multstart_progress <- function(formula, data = parent.frame(), iter, start_lower, 
                                   start_upper, supp_errors = c("Y", "N"), convergence_count = 100, 
                                   control, modelweights, ...){
  if(!is.null(pb)){
    pb$tick()
  }
  nls_multstart(formula = formula, data = data, iter = iter, start_lower = start_lower, 
                start_upper = start_upper, supp_errors = supp_errors, convergence_count = convergence_count, 
                control = control, modelweights = modelweights, ...)
}

# start progress bar and estimate time it will take
number_of_models <- 1
number_of_curves <- length(unique(Respdata$Number))

# setup progress bar
pb <- progress::progress_bar$new(total = number_of_curves*number_of_models,
                                 clear = FALSE,
                                 format ="[:bar] :percent :elapsedfull")

# fit  chosen model formulation in rTPC
d_fits <- Respdata %>% group_by(fragment_ID...1) %>% nest() %>%
  mutate(sharpeschoolhigh = map(data, ~nls_multstart(transformed.rate~sharpeschoolhigh_1981(temp = Temp.Cat, r_tref,e,eh,th, tref = 28),
                        data = .x,
                        iter = c(3,3,3,3),
                        start_lower = start_vals - 1,
                        start_upper = start_vals + 1,
                        lower = low_lims,
                        upper = upper_lims,
                        supp_errors = 'Y',
                        convergence_count = FALSE)))


```

```{r}
# create new list column of for high resolution data
d_preds <- mutate(d_fits, new_data = map(data, ~tibble(temp = seq(min(.x$temp), max(.x$temp), length.out = 50)))) %>%
  # get rid of original data column
  select(., -data) %>%
  # stack models into a single column, with an id column for model_name
  pivot_longer(., names_to = 'model_name', values_to = 'fit', sharpeschoolhigh) %>%
  # create new list column containing the predictions
  # this uses both fit and new_data list columns
  mutate(preds = map2(fit, new_data, ~augment(.x, new_data = .y))) %>%
  # select only the columns we want to keep
  select(fragment_ID, preds) %>%
  # unlist the preds list column
  unnest(preds)

glimpse(d_preds)
```


```{r}
ggplot(d_preds) +
  geom_line(aes(Temp.Cat, .fitted)) +
  geom_point(aes(Temp.Cat, transformed.rate), Respdata) +
  facet_wrap(~fragment_ID, scales = 'free_y', ncol = 6) +
  theme_bw() +
  theme(legend.position = 'none') +
  scale_color_brewer(type = 'qual', palette = 2) +
  labs(x = 'Temperature (ÂºC)',
       y = 'Metabolic rate',
       title = 'All fitted thermal performance curves',
       subtitle = 'sharpeschoolhigh in orange')


```

```{r}
d_params <- pivot_longer(d_fits, names_to = 'model_name', values_to = 'fit', sharpeschoolhigh) %>%
  mutate(params = map(fit, calc_params)) %>%
  select(fragment_ID, params) %>%
  unnest(params)

glimpse(d_params)
```